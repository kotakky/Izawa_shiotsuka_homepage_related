<!DOCTYPE html>
<html lang="jp">
<!-- Basic -->

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <!-- Mobile Metas -->
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <!-- Site Metas -->
    <title>Kamijo Lab - UTokyo</title>
    <meta name="keywords" content="ITS, AI, IIS, Intelligent vehicles, autonomous vehicles, AV, Self-driving car, customer, customer behaviour, hd map, 3d map, point cloud map, pcd,
    map matching, itsc, deep learning, scene understanding, gnss, gps, 3d-gnss, 3d aided gnss, III, u-tokyo, the university of tokyo, gan, kamijo, Kamijo Laboratory, Kamijo Shunsuke, University of Tokyo, ITS, Autonomous Driving, GPS, Indoor positioning, 
			  Marketing,  HD map, self-driving cars, self-driving, map, Mobile Devices, driver data recorder, customer behaviour understanding, custumer 
			  behaviour, social network analysis, pdr, pedestrian dead reckoning, pedestrian behaviour understanding, GNSS, MMS, mobile mapping system, point cloud, 
			  3D gnss, mms calibration, map evaluation">
	
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- Site Icons -->
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
    <link rel="apple-touch-icon" href="#" />

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="css/bootstrap.min.css" />
    <!-- Pogo Slider CSS -->
    <link rel="stylesheet" href="css/pogo-slider.min.css" />
    <!-- Site CSS -->
    <link rel="stylesheet" href="css/style.css" />
    <!-- Responsive CSS -->
    <link rel="stylesheet" href="css/responsive.css" />
    <!-- Custom CSS -->
    <link rel="stylesheet" href="css/custom.css" />

    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body id="contact" class="inner_page" data-spy="scroll" data-target="#navbar-wd" data-offset="98">

    <!-- LOADER -->
    <div id="preloader">
        <div class="loader">
            <img src="images/loader.gif" alt="#" />
        </div>
    </div>
    <!-- end loader -->
    <!-- END LOADER -->

    <!-- Start header -->
    <header class="top-header">
        <nav class="navbar header-nav navbar-expand-lg">
            <div class="container-fluid">
                <a class="navbar-brand" href="index.html"><img src="img/home/kmjlab_logo.png" alt="image" style="height:60px"></a>
                <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-wd" aria-controls="navbar-wd" aria-expanded="false" aria-label="Toggle navigation">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
                <div class="collapse navbar-collapse justify-content-end" id="navbar-wd">
                    <ul class="navbar-nav">
                        <li><a class="nav-link active" href="e_index.html">Home</a></li>
                        <li><a class="nav-link" href="e_research.html">Research</a></li>
                        <li><a class="nav-link" href="e_publications.html">Publications</a></li>
                        <li><a class="nav-link" href="contact.html">Members</a></li>
                        <li><a class="nav-link" href="accessver2.html">Access</a></li>
						            <li><a class="nav-link" href="contact.html">For students</a></li>
                        <li><a class="nav-link" href="e_access.html"style="background:#61892F;color:#fff;" href="index.html">English</a></li>
                        <!-- <li><a class="nav-link active" style="background:#61892F;color:#fff;" href="index.html">English</a></li>-->
                    </ul>
                </div>
                <div class="search-box">
                    <input type="text" class="search-txt" placeholder="Search">
                    <a class="search-btn">
                        <img src="img/icons/search_icon.png" alt="#" />
                    </a>
                </div>
            </div>
        </nav>
    </header>
    <!-- End header -->

    <!-- Start Banner -->
	  <div class="section inner_page_header">
	     <div class="container">
		    <div class="row">
              <div class="col-lg-12">
			     <div class="full">
				    <h3>Research</h3>
				 </div>
			  </div>
			</div>
		 </div>
	  </div>
    <!-- end Banner -->
	
	<!-- section -->
    <div class="section layout_padding">
      <div class="container">
      <Hr>
      <center>
      <b><h11><span class="theme_color">　Autonomous Driving</span></h11></b>
      </center>
      <Hr> 

      
      <div style="margin-bottom:50px;">
        <div class="row">
          <div class="full">
              <div class="heading_main text_align_left">
						    <div class="left">
						      
                  <h44><span class="theme_color">　Self-Localization</span></h44>
                </div>
              </div>
            </div>
        </div>
        <p>
	For autonomous driving vehicles, Intelligent Transport Systems (ITS) and smartphone applications, it is important to determine one's location accurately. Under this theme, we are aiming to establish methods to determine location precisely using such technologies as GPS, GNSS (Global Navigation Satellite System), inertia sensor mounted in a car, mobile device sensors among others. Focus is placed especially on localization in urban environments.
      
        <li><u><a class="nav-link" href="researchpages/j_GNSS Error Correction Using 3D Maps in Urban Canyons.html"><h43>GNSS Error Correction Using 3D Maps in Urban Canyons</h43></a></u></li>
	Using 3D maps and ray tracing, we corrected multipath and NLOS propagation delay, which are the main cause for GNSS error in urban environments. In addition, we could determine the location more accurately using Multi-GNSS and L1-SAIF signal information among others.
        <li><u><a class="nav-link" href="researchpages/j_self-localization using 2D map and LiDAR.html"><h43>Self-localization using 2D map and LiDAR</h43></a></u></li>
	Localization using GNSS in urban environments is not accurate enough in most cases. State-of-the-art self-localization includes methods such as matching 3D map and LiDAR data, but creating 3D maps is not a simple process. Instead, we used 2D maps and LiDAR as a method for self-localization.
        <li><u><a class="nav-link" href="j_researchpages/j_self-localization using 2D map and LiDAR.html"><h43>Map evaluation for self-localization</h43></a></u></li>
	Matching LiDAR and map data for the purpose of self-localization is a technology which has gathered attention in the research community. In this research we focused on map, which is the main cause for self-localization error, and conducted a completely novel evaluation of a map in various situations.
        <li><u><a class="nav-link" href="j_researchpages/j_GNSS_INS_On-BoardCamera Integration for Autonomous Vehicle Self-Localization in Urban Environment.html"><h43>GNSS_INS_On-BoardCamera Integration for Autonomous Vehicle Self-Localization in Urban Environment</h43></a></u></li>
	Fusing vehicle speed sensor and gyro sensor etc. with GNSS positioning, we achieve more precise self-localization of a vehicle.

        
        <!--
        <div class = "research_img4">
        <img src="img/research/AD/a1.png">
        <img src="img/home/Customer-Behaviour3.jpg">
        <img src="img/home/Customer-Behaviour3.jpg">
        <img src="img/home/Customer-Behaviour3.jpg">
        </div>  
        -->    
      </div>
      

    <div style="margin-bottom:50px;">
        <div class="row">
          <div class="full">
              <div class="heading_main text_align_left">
						    <div class="left">
						      
                  <h44><span class="theme_color">　Generation and Application of 3D Map</span></h44>
                </div>
              </div>
            </div>
        </div>
        <p>
	A 3D map is essential for self-localization using cameras and laser systems, in addition to our high accuracy GNSS positioning method. The accuracy of a 3D map greatly affects the result of self-localization, and under this theme, we research methods on creating and improving 3D maps.
        </p>   
        
        <li><u><a class="nav-link" href="researchpages/j_3D Building Map Reconstruction by Integrating Airborne Laser Point Cloud with 2D Boundary map.html"><h43>3D Building Map Reconstruction by Integrating Airborne Laser Point Cloud with 2D Boundary map</h43></a></u></li>
	From a big 3D point cloud collected by MMS, we extract 2D borders of a building while conducting research on methods to create simpler but still detailed enough 3D maps.
        <li><u><a class="nav-link" href="researchpages/j_3D Building Map Reconstruction by Integrating Airborne Laser Point Cloud with 2D Boundary map.html"><h43>3D Building Map Reconstruction by Integrating Airborne Laser Point Cloud with 2D Boundary map</h43></a></u></li>
	Using characteristics of a road obtained from an aerial 3D point cloud data, we propose a framework to automatically match MMS data with an aerial map.
        <li><u><a class="nav-link" href="researchpages/j_Correction of Building Footprint for 3D City Models using GNSS Measurement.html"><h43>Correction of Building Footprint for 3D City Models using GNSS Measurement</h43></a></u></li>
	Using our GNSS positioning, we research a method to correct location error of a building in a 3D map
        <!--
        <li><u><a class="nav-link" href="researchpages/j_Correction of Building Footprint for 3D City Models using GNSS Measurement.html"><h43>HD mapに関する研究</h43></a></u></li>
        izawakunに相談する
        -->
        <!--
        <div class = "research_img">
        <img src="img/home/Customer-Behaviour3.jpg">
        <img src="img/home/Customer-Behaviour3.jpg">
        <img src="img/home/Customer-Behaviour3.jpg">
        </div>
        -->
      </div>
			
    <div style="margin-bottom:50px;">
        <div class="row">
          <div class="full">
              <div class="heading_main text_align_left">
						    <div class="left">
                
                  <h44><span class="theme_color">　Detection of Pedestrian/Cyclist </span></h44>
                </div>
              </div>
            </div>
        </div>
        <p>
	When it comes to autonomous driving and Advanced Driving Assistance Systems (ADAS), it is vital to ensure the safety of pedestrians, cyclists and other vulnerable parties in traffic. At our laboratory, we approach this subject through such methods as pedestrian and cyclist detection, behaviour recognition among others.
        </p>   
        
        <li><u><a class="nav-link" href="researchpages/Pedestrian Detection by On-board Vision Sensor.html"><h43>Pedestrian Detection by On-board Vision Sensor</h43></a></u></li>
        Combining <u><a href="researchpages/ST-MRF.html">Space-time MRF model (ST-MRF)</a></u> foreground object detection and HOG feature value algorithms, we conduct the detection of pedestrians only from an onboard vehicle camera feed.
        <li><u><a class="nav-link" href="researchpages/Recognition and Pose Estimation of Urban Road Users from On-board Cameras.html"><h43>Recognition and Pose Estimation of Urban Road Users from On-board Cameras</h43></a></u></li>
        After detecting pedestrians and cyclists, we estimate their attention and movement direction using HOG feature value, SVM and restriction conditions.
        <li><u><a class="nav-link" href="researchpages/Pedestrian Detection Using RSSI.html"><h43>Pedestrian Detection Using RSSI</h43></a></u></li>
	Using received signal strength indication (RSSI) as a base, we estimate the relative position of a pedestrian with regards to a vehicle.
        <li><u><a class="nav-link" href="researchpages/Pedestrian Self-localization Using Mobile Devices.html"><h43>Pedestrian Self-localization Using Mobile Devices</h43></a></u></li>
	Using acceleration sensor and magnetic sensor commonly found in smartphones, we detect pedestrian movement (step width, direction) and additively calculate their relative position (pedestrian dead reckoning). In addition, by fusing the data with GPS we can accurately measure their location.
        <!--
        <div class = "research_img4">
            <img src="img/researchpages\AD\Estimation of PedestrianCyclist/Pedestrian Detection by On-board Vision Sensor\Pedestrian Detection by On-board Vision Sensor1.jpg">
            <img src="img\researchpages\AD\Estimation of PedestrianCyclist\Recognition and Pose Estimation of Urban Road Users from On-board Cameras/Recognition and Pose Estimation3.jpg">
            <img src="img\researchpages\AD\Estimation of PedestrianCyclist\Pedestrian Detection Using RSSI/RSII0.jpg">
            <img src="img\researchpages\AD\Estimation of PedestrianCyclist\Pedestrian Self-localization Using Mobile Devices/Pedestrian self-localization1.jpg">
        </div>  
        -->
                 
      </div>

      
        <div style="margin-bottom:50px;">
            <div class="row">
              <div class="full">
                  <div class="heading_main text_align_left">
                                <div class="left">
                                  
                      <h44><span class="theme_color">　Scene Understanding and Motion Planning at Intersections</span> </h44>
                    </div>
                  </div>
                </div>
            </div>
            <p>
            In autonomous driving, understanding the situation at an intersection and the vehicle reacting to it accordingly (motion planning) is an important task. At our laboratory, we research the scene recognition and motion planning in a complex urban intersection. 
            </p>   

            <li><u><a class="nav-link" href="researchpages/j_Pedestrian Behavior Recognition at Signalized Intersections.html"><h43>Pedestrian Behavior Recognition at Signalized Intersections</h43></a></u></li>
            Through a model taking in consideration the various scenes of a signal intersection, we estimate the movement of a pedestrian who might dash or stop suddenly at the intersection.
            <li><u><a class="nav-link" href="researchpages/j_scene understanding at Intersections.html"><h43>Scene understanding at intersections</h43></a></u></li>
            We propose an approach of using stereo vision and digital 3D map as a basis to analyze the traffic situation at an urban intersection in both space and time dimensions.
            <li><u><a class="nav-link" href="researchpages/j_human-like motion planning at Intersections.html"><h43>Human-like motion planning at intersections</h43></a></u></li>
            In autonomous driving, sudden deceleration is not good in terms of passenger comfort and effect on nearby vehicles. To deal with this, we propose a more human-like motion planning which takes into consideration the traffic situation and environment around the vehicle.
            <!--
            <div class = "research_img">
            <img src="img\researchpages\AD\Risk assessment\Pedestrian Behavior Recognition at Signalized Intersections/Pedestrian Behavior Recognition at Signalized Intersections0.jpg">
            <img src="img\researchpages\AD\Risk assessment\risk assesment at Intersections/risk assesment at Intersections0.jpg">
            </div>
            -->
                
        </div>
      

     

      <div style="margin-bottom:50px;">
        <div class="row">
          <div class="full">
              <div class="heading_main text_align_left">
						    <div class="left">
						      
                  <h44><span class="theme_color">　Risk Assessment</span> </h44>
                </div>
              </div>
            </div>
        </div>
        <p>
        To realize both safe and comfortable autonomous driving, it is important to recognize potentially risky driving scenes and react to them accordingly by decelerating and using proper motion planning. This can prevent an accident or a near-miss situation before it occurs while maintaining a comfortable user experience for the passenger. At our laboratory we examine and assess the risk level of various driving scenes.
        </p>   
        
        <li><u><a class="nav-link" href="researchpages/j_risk assesment.html"><h43>Risk assessment of driving environment</h43></a></u></li>
        Using weak supervised learning, we propose an end-to-end model to classify the risk level of a driving scene in three categories.
        
        <!--
        <div class = "research_img">
        <img src="img\researchpages\AD\Risk assessment\Pedestrian Behavior Recognition at Signalized Intersections/Pedestrian Behavior Recognition at Signalized Intersections0.jpg">
        <img src="img\researchpages\AD\Risk assessment\risk assesment at Intersections/risk assesment at Intersections0.jpg">
        </div>
        -->
            
      </div>    

      <Hr>       
      <center>
      <h11><b>マーケティング<span class="theme_color">　Marketing</span> </b></h11>
      </center>
      <Hr> 
      <div style="margin-bottom:50px;">
        <div class="row">
          <div class="full">
              <div class="heading_main text_align_left">
						    <div class="left">
						     
                  <h44><span class="theme_color">　Customer Pose Estimation from Surveillance Camera</span></h44>
                </div>
              </div>
            </div>
        </div>
        <p>
	In marketing, it is important to estimate the interest level of a customer towards a product.
	To estimate the interest level of a customer, we conduct behaviour recognition and pose estimation of the customer using cameras installed inside the store.
        </p>   
        <li><u><a class="nav-link" href="researchpages/j_customer detecition.html"><h43>Human behaviour recognition in marketing</h43></a></u></li>
        We conduct research on methods to estimate the interest level towards a product and behaviour recognition of a customer in retail shops using cameras.
        <li><u><a class="nav-link" href="researchpages/j_Customer Pose estimation.html"><h43>Customer pose estimation</h43></a></u></li>
        In estimating customer's interest level, their body direction plays an important role. At our laboratory, we propose a system using surveillance camera and space-time deep neural network model to estimate customer's pose.
        <li><u><a class="nav-link" href="researchpages/j_Occulusion aware customer pose estimation.html"><h43>Occulusion aware customer pose estimation</h43></a></u></li>
        Joint estimation often used in pose estimation is not usually accurate in case of an occlusion. Therefore we propose a multiple people pose estimation method using Mask Region based Convolutional Neural Network (Mask R-CNN).
        <li><u><a class="nav-link" href="researchpages/j_Understanding Pedestrian Behaivior in Railway Station.html"><h43>Understanding Pedestrian Behaviour inside Railway Station</h43></a></u></li>
        Combining object pose information with location information, we built a framework for human behaviour recognition inside a railway station.
       
        <!--
        <div class = "research_img">
        <img src="img/home/Customer-Behaviour3.jpg">
        <img src="img/home/Customer-Behaviour3.jpg">
        <img src="img/home/Customer-Behaviour3.jpg">
        </div>
        -->
              
      </div>   

     

      <div style="margin-bottom:50px;">
        <div class="row">
          <div class="full">
              <div class="heading_main text_align_left">
						    <div class="left">
						     
                  <h44><br><span class="theme_color">　Human Positioning and Activity Estimation using Smartphone Sensors</span></h44>
                </div>
              </div>
            </div>
        </div>
        <p>
        GPS and surveillance cameras are often used for human location estimation and behaviour recognition.
	However, GPS tends to lose accuracy inside a large indoor environment such as a department store, while installing surveillance cameras to cover all indoor areas is very expensive.
	Because of that, we propose a system for human behaviour recognition using indoor location information gained from smartphone sensors.
        <br>
        </p>   
        <li><u><a class="nav-link" href="researchpages/j_Indoor positioning.html"><h43>Indoor Positioning</h43></a></u></li>
        GPS based localization loses accuracy in indoor environments such as shopping malls. To address this, we propose an accurate indoor localization system using context-based map matching and smartphone sensors inside a large-scale indoor environment.
        <li><u><a class="nav-link" href="researchpages/j_Human avtivity.html"><h43>Human Behaviour Recognition and Smartphone State Estimation</h43></a></u></li>
        Using only smartphone sensors, we estimate human behaviour based on three main activities (sit/stand/walk) and six types of modes (swinging/handling/calling/inside a pocket/inside a handbag/inside a backpack).
        <li><u><a class="nav-link" href="researchpages/j_Lifelog.html"><h43>Location Information Based User Lifelog</h43></a></u></li>
        Smartphones have the ability to record where we go and where we are at a given moment. However, the information is recorded in longitudinal and latitudinal coordinates, and is therefore hard to understand intuitively. At our laboratory we use this information to estimate user location and activity.
       
        
        <!--
        <div class = "research_img">
        <img src="img/home/Customer-Behaviour3.jpg">
        <img src="img/home/Customer-Behaviour3.jpg">
        </div>
        -->
        
             
        </div>   


      <div style="margin-bottom:50px;">
        <div class="row">
          <div class="full">
              <div class="heading_main text_align_left">
						    <div class="left">
						     
                  <h44><span class="theme_color">　Navigation using Wearable Glass</span></h44>
                </div>
              </div>
            </div>
        </div>
        <p>
        Using wearable smart glass, we combine our pedestrian localization method and image matching technology to achieve high accuracy localization. Furthermore, we aim to provide a new navigation experience by applying augmented reality (AR) technology to localization.
        </p>   
        
        <li><u><a class="nav-link" href="j_researchpages/accessver2.html"><h43>Navigation using Wearable Glass</h43></a></u></li>
        By developing smart glass navigation, we provide a new pedestrian experience.
       
        <!--
        <div class = "research_img">
        <img src="img/home/Customer-Behaviour3.jpg">
        
        </div>
        -->

      </div> 
      <Hr>
      <center>
      <h11><b><span class="theme_color">　Generative Adversarial Networks</span></b></h11>
      </center>
      <Hr> 
      <div style="margin-bottom:100px;">
        <div class="row">
          <div class="full">
              <div class="heading_main text_align_left">
						    <div class="left">
						     
                  <h44><span class="theme_color">　A Latent Space Understandable Generative Adversarial Networks</span></h44>
                </div>
              </div>
            </div>
        </div>
        <p>
        Generative Adversarial Networks (GANs) has gained a lot of attention in recent years and is expected to be widely used in the future. At our laboratory we research GANs and its various practical applications.<br>
        </p>   
        
         <li><u><a class="nav-link" href="researchpages/j_GANs.html"><h43>GANs latent space research</h43></a></u></li>
        We propose latent space understanding Self-excited Generative Adversarial Network（SelfExGAN), which is capable of not only learning to create new samples but also to understand the relationship between hidden input and training data.
       
        <!--
        <div class = "research_img">
        <img src="img\researchpages\DL\GANs\GANs0.jpg">
        </div>
        
        <br clear="both"/>
        -->
        
            
      </div>          

      <Hr>
      <center>
      <h11><b><span class="theme_color">　Traffic Infrastructure</span></b></h11>
      </center>
      <Hr> 
      <div style="margin-bottom:50px;">
        <div class="row">
          <div class="full">
              <div class="heading_main text_align_left">
						    <div class="left">
						     
                  <h44><span class="theme_color">　Traffic Surveillance </span></h44>
                </div>
              </div>
            </div>
        </div>
        <p>
	In recent years, surveillance cameras have been installed in road environments for example to measure the amount of traffic and to detect traffic accidents. At our laboratory, we conducted research about technology which automatically extracts relevant information from surveillance camera feed without the need for human intervention.
        </p>   
        <li><u><a class="nav-link" href="j_researchpages/accessver2.html"><h43>Traffic flow measurement</h43></a></u></li>
        Using occlusion-robust tracking techniques, we developed a system which automatically obtains direction, average speed, traffic intensity and other traffic relevant statistics.
        <li><u><a class="nav-link" href="j_researchpages/accessver2.html"><h43>Unusual traffic event monitoring</h43></a></u></li>
        In the field of traffic flow monitoring, we built a system which detects accidents, traffic congestion, stopped vehicles, fallen objects and other such traffic related phenomenons in real-time using video from a camera as an input and applying image processing techniques.
        <!--
        <div class = "research_img">
        <img src="img/home/Customer-Behaviour3.jpg">
        <img src="img/home/Customer-Behaviour3.jpg">
        </div>
        -->
               
      </div>          

      <div style="margin-bottom:30px;">
        <div class="row">
          <div class="full">
              <div class="heading_main text_align_left">
						    <div class="left">
						      
                  <h44><span class="theme_color">　Traffic Signal Control</span> </h44>
                </div>
              </div>
            </div>
        </div>
        <p>
        Previous traffic signal control had fixed cycle length and split parameter values, which caused problems such as unnecessary waiting time due to red lights even when there was virtually no traffic. In this regards, we conducted research regarding a cooperative-type intersection control method.
        </p>   
        <li><u><a class="nav-link" href="j_researchpages/accessver2.html"><h43>Intersection traffic signal control using image sensor</h43></a></u></li>
        We proposed that an advanced image sensor, which measures both vehicles and pedestrians, is helpful in the optimization of traffic signal split for vehicles and pedestrians.
        <!--
        <div class = "research_img">
        <img src="img/home/Customer-Behaviour3.jpg">
        </div>
        -->
               
      </div>




      </div>
    </div>
	<!-- end section -->
	

   <!-- Start Footer -->
    <footer class="footer-box">
        <div class="container">
            <div class="row">
                <div class="col-md-12 margin-bottom_30">
				              <img src="img/home/kmjlab_logo.png" style="height:60px" alt="#" />
				        </div>
                <div class="col-xl-6 white_fonts">
                    <div class="row">
            					<div class="col-md-12 white_fonts margin-bottom_30">
            					   <h3>Contact Us</h3>
            					</div>
                        <div class="col-md-6">
                            <div class="full icon">
                                <img src="img/icons/social1.png">
                            </div>
                            <div class="full white_fonts">
                                <!--p>Kamijo Laboratory, Laboratory:Ew-403/404, Professor's room:Ee-406, 4th floor, E Block, Institute of Industrial Science, 4-6-1 Komaba,Meguro-ku,Tokyo
                                <br>153-8505 Japan</p-->
                                <p>
                                  上條研究室<br>東京都目黒区4-6-1 駒場<br>生産技術研究所 Ew403<br></p>
                            </div>
                        </div>
                        <div class="col-md-6">
                            <div class="full icon">
                                <img src="img/icons/social2.png">
                            </div>
                            <div class="full white_fonts">
                                <p>kamijo[at]iis.u-tokyo.ac.jp</p>
                            </div>

                            <div class="full icon">
                                <img src="img/icons/social3.png">
                            </div>
                            <div class="full white_fonts">
                                <p>03-5452-6273, 03-5452-6272</p>
                            </div>
                        </div>

					
                    </div>
                </div>

				 <div class="col-xl-6 white_fonts">
				    <div class="row">
					   <div class="col-md-6">
					     <div class="footer_blog footer_menu">
						    <h3>Menus</h3>
						    <ul>
							  <li><a href="index.html">Home</a></li>
							  <li><a href="">Research</a></li>
							  <li><a href="http://kmj.iis.u-tokyo.ac.jp/e_publications.html">Publications</a></li>
							  <li><a href="http://kmj.iis.u-tokyo.ac.jp/e_access.html">Members</a></li>
                              <li><a href="http://kmj.iis.u-tokyo.ac.jp/e_access.html">Access</a></li>
							  <li><a href="http://kmj.iis.u-tokyo.ac.jp/e_linkforstudents.html">For students</a></li>
                <li><a href="http://kmj.iis.u-tokyo.ac.jp/index.html">English</a></li>
							</ul>
						 </div>
						 <div class="footer_blog recent_post_footer">
						   <h3>U Tokyo Links</h3>
						   <p>Graduate School of Information Science and Technology</p>
               <p>Graduate School of Interdisciplinary Information Studies</p>
						 </div>
					   </div>
					   <div class="col-md-6">
					     <div class="footer_blog full">
						     <h3>Apply to KMJ lab</h3>
							 <div class="newsletter_form">
							    <form action="index.html">
						
								   <button>Apply</button>
								</form>
							 </div>
						 </div>
					   </div>
					</div>
				 </div>

            </div>

        </div>
    </footer>
    <!-- End Footer -->

    <div class="footer_bottom">
        <div class="container">
            <div class="row">
                <div class="col-12">
                    <p class="crp">© 2020 Business . All Rights Reserved.</p>
                    <ul class="bottom_menu">
                        <li><a href="#">Term of Service</a></li>
                        <li><a href="#">Privacy</a></li>
                    </ul>
                </div>
            </div>
        </div>
    </div>

    <a href="#" id="scroll-to-top" class="hvr-radial-out"><i class="fa fa-angle-up"></i></a>

    <!-- ALL JS FILES -->
    <script src="js/jquery.min.js"></script>
	<script src="js/popper.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <!-- ALL PLUGINS -->
    <script src="js/jquery.magnific-popup.min.js"></script>
    <script src="js/jquery.pogo-slider.min.js"></script>
    <script src="js/slider-index.js"></script>
    <script src="js/smoothscroll.js"></script>
    <script src="js/form-validator.min.js"></script>
    <script src="js/contact-form-script.js"></script>
    <script src="js/isotope.min.js"></script>
    <script src="js/images-loded.min.js"></script>
    <script src="js/custom.js"></script>
	<script>
	/* counter js */

(function ($) {
	$.fn.countTo = function (options) {
		options = options || {};
		
		return $(this).each(function () {
			// set options for current element
			var settings = $.extend({}, $.fn.countTo.defaults, {
				from:            $(this).data('from'),
				to:              $(this).data('to'),
				speed:           $(this).data('speed'),
				refreshInterval: $(this).data('refresh-interval'),
				decimals:        $(this).data('decimals')
			}, options);
			
			// how many times to update the value, and how much to increment the value on each update
			var loops = Math.ceil(settings.speed / settings.refreshInterval),
				increment = (settings.to - settings.from) / loops;
			
			// references & variables that will change with each update
			var self = this,
				$self = $(this),
				loopCount = 0,
				value = settings.from,
				data = $self.data('countTo') || {};
			
			$self.data('countTo', data);
			
			// if an existing interval can be found, clear it first
			if (data.interval) {
				clearInterval(data.interval);
			}
			data.interval = setInterval(updateTimer, settings.refreshInterval);
			
			// initialize the element with the starting value
			render(value);
			
			function updateTimer() {
				value += increment;
				loopCount++;
				
				render(value);
				
				if (typeof(settings.onUpdate) == 'function') {
					settings.onUpdate.call(self, value);
				}
				
				if (loopCount >= loops) {
					// remove the interval
					$self.removeData('countTo');
					clearInterval(data.interval);
					value = settings.to;
					
					if (typeof(settings.onComplete) == 'function') {
						settings.onComplete.call(self, value);
					}
				}
			}
			
			function render(value) {
				var formattedValue = settings.formatter.call(self, value, settings);
				$self.html(formattedValue);
			}
		});
	};
	
	$.fn.countTo.defaults = {
		from: 0,               // the number the element should start at
		to: 0,                 // the number the element should end at
		speed: 1000,           // how long it should take to count between the target numbers
		refreshInterval: 100,  // how often the element should be updated
		decimals: 0,           // the number of decimal places to show
		formatter: formatter,  // handler for formatting the value before rendering
		onUpdate: null,        // callback method for every time the element is updated
		onComplete: null       // callback method for when the element finishes updating
	};
	
	function formatter(value, settings) {
		return value.toFixed(settings.decimals);
	}
}(jQuery));

jQuery(function ($) {
  // custom formatting example
  $('.count-number').data('countToOptions', {
	formatter: function (value, options) {
	  return value.toFixed(options.decimals).replace(/\B(?=(?:\d{3})+(?!\d))/g, ',');
	}
  });
  
  // start all the timers
  $('.timer').each(count);  
  
  function count(options) {
	var $this = $(this);
	options = $.extend({}, options || {}, $this.data('countToOptions') || {});
	$this.countTo(options);
  }
});
	</script>
</body>

</html>